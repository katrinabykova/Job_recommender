{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:16.658040Z",
     "start_time": "2019-11-14T19:55:12.375528Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "import textcleaner\n",
    "import pickle\n",
    "import spacy\n",
    "import jieba\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import textcleaner as tc\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "import spacy\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "from src.models import display_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:16.872529Z",
     "start_time": "2019-11-14T19:55:16.662775Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:23.046371Z",
     "start_time": "2019-11-14T19:55:16.875512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/greenapple/project4\n",
      "Installing collected packages: src\n",
      "  Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src\n"
     ]
    }
   ],
   "source": [
    "! pip install --editable .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:23.601933Z",
     "start_time": "2019-11-14T19:55:23.058647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load tokenized text\n",
    "pickling_out = open('/Users/greenapple/project4/data/processed/jobs_tokenized.pkl', 'rb')\n",
    "jobs = pickle.load(pickling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:23.712179Z",
     "start_time": "2019-11-14T19:55:23.608955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8939, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T01:21:42.208500Z",
     "start_time": "2019-11-11T01:21:42.153478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_name', 'description', 'job_title', 'link', 'location',\n",
       "       'salary', 'type', 'clean_text', 'noun', 'noun_lemma', 'lemma', 'word'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:46.400421Z",
     "start_time": "2019-11-14T19:55:46.238797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5058, 12), (8939, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data scientist/analyst jobs only\n",
    "jobs_d = jobs.loc[jobs.type=='positive']\n",
    "jobs_d.shape, jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T19:55:49.392540Z",
     "start_time": "2019-11-14T19:55:49.228193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_name', 'description', 'job_title', 'link', 'location',\n",
       "       'salary', 'type', 'clean_text', 'noun', 'noun_lemma', 'lemma', 'word'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:48:01.817404Z",
     "start_time": "2019-11-10T22:48:01.753750Z"
    }
   },
   "source": [
    "### Noun as a token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF and LSA with Noun as token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:11:35.842463Z",
     "start_time": "2019-11-14T21:11:35.785964Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.stop_words_list_1 import stop_words_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:16:04.134729Z",
     "start_time": "2019-11-14T21:16:02.619906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bike', 'citizen', 'enforcement', 'government', 'hood', 'law', 'management', 'marketing', 'offerings', 'parking', 'prevention', 'seattle', 'table', 'tennis', 'views', 'waterfront', 'ways', 'world'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2689\n",
      "[0.07273745 0.11360044 0.07922137 0.07281772 0.07521817 0.0727262\n",
      " 0.06721486 0.06567128 0.04586941 0.03427465 0.02969788 0.02876408\n",
      " 0.02479424 0.02367738 0.01656202 0.01502156 0.01387867 0.01330501\n",
      " 0.00869666 0.00440473]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_tf_idf_LSA_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>statistics, machine, modeling, engineers, warehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>warehouse, database, azure, databricks, pipelines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>game, visualization, sql, visualization taxonomy, experimentation breadth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>clients, transportation, management, recommendations, splunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>production, splunk, ididata, resolution algorithms, waterfront views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>airlines, information, splunk, visualization, energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>query, knowledge operation, system problem, questions information, errors engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>splunk, concepts splunk, deployment management, telecommunications, communications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>energy, energy energy, forecasting, cloud, simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>documentation, training, awc, documentation training, security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>query, names, users, assignment ambiguity, ambiguities assignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>move maintenance, types remodels, move, remodels, remodels professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>algorithms pipelines, pipelines recommendations, content delivery, marketing algorithms, recommendations content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>writing contractsalary, capacity objectives, conclusions visualization, configuration reporting, degree scienceproven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>machine, intelligence, agency, security, managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>machine, machine language, language understanding, language, intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>charlies, stock, college, tableau, dashboards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>resources, families, neighbor, kaleidoscope, community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>languages, engineering, analyses, world, field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>qualities, coaching, demand, network, communication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        noun_tf_idf_LSA_1\n",
       "0                                                                     statistics, machine, modeling, engineers, warehouse\n",
       "1                                                                       warehouse, database, azure, databricks, pipelines\n",
       "2                                               game, visualization, sql, visualization taxonomy, experimentation breadth\n",
       "3                                                            clients, transportation, management, recommendations, splunk\n",
       "4                                                    production, splunk, ididata, resolution algorithms, waterfront views\n",
       "5                                                                    airlines, information, splunk, visualization, energy\n",
       "6                                     query, knowledge operation, system problem, questions information, errors engineers\n",
       "7                                      splunk, concepts splunk, deployment management, telecommunications, communications\n",
       "8                                                                   energy, energy energy, forecasting, cloud, simulation\n",
       "9                                                          documentation, training, awc, documentation training, security\n",
       "10                                                      query, names, users, assignment ambiguity, ambiguities assignment\n",
       "11                                                move maintenance, types remodels, move, remodels, remodels professional\n",
       "12       algorithms pipelines, pipelines recommendations, content delivery, marketing algorithms, recommendations content\n",
       "13  writing contractsalary, capacity objectives, conclusions visualization, configuration reporting, degree scienceproven\n",
       "14                                                                      machine, intelligence, agency, security, managers\n",
       "15                                              machine, machine language, language understanding, language, intelligence\n",
       "16                                                                          charlies, stock, college, tableau, dashboards\n",
       "17                                                                 resources, families, neighbor, kaleidoscope, community\n",
       "18                                                                         languages, engineering, analyses, world, field\n",
       "19                                                                    qualities, coaching, demand, network, communication"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name: ***noun_tf_idf_LSA_1***\n",
    "# Tokenizer: noun\n",
    "# Vectorizer: TF-IDF\n",
    "# Dimensionality reduction: LSA\n",
    "\n",
    "tf_idf_vc_1 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            max_df = 0.7,\n",
    "                            min_df = 0.005,\n",
    "                            stop_words = stop_words_1)   \n",
    "\n",
    "components = 20  # number of LSA components\n",
    "lsa_1 = TruncatedSVD(components, random_state = 5)\n",
    "\n",
    "\n",
    "topics = lsa_1.fit_transform(tf_idf_vc_1.fit_transform(jobs_d.noun).toarray())  # reduce dimensionality\n",
    "\n",
    "print(len(tf_idf_vc_1.vocabulary_))   # number of words in dictionary\n",
    "print(lsa_1.explained_variance_ratio_)      # explained variance\n",
    "\n",
    "# pd.DataFrame(tf_idf_vc_1.fit_transform(jobs.noun).toarray(), columns=tf_idf_vc_1.get_feature_names()).head(10)\n",
    "\n",
    "# lsa_1.components_\n",
    "# tf_idf_vc_1.get_feature_names()\n",
    "\n",
    "noun_tf_idf_LSA_1 = display_topics.topics_to_df(lsa_1, tf_idf_vc_1.get_feature_names(), 5, 'noun_tf_idf_LSA_1')  # save topics\n",
    "\n",
    "pd.set_option('max_colwidth', 200)  # display strings\n",
    "noun_tf_idf_LSA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T20:54:12.196406Z",
     "start_time": "2019-11-14T20:54:12.137278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T19:03:05.995582Z",
     "start_time": "2019-11-09T19:03:05.991842Z"
    }
   },
   "source": [
    "#### TF-IDF and NMF with Noun as token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:38:44.225440Z",
     "start_time": "2019-11-10T22:38:29.567018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bike', 'parking', 'views', 'waterfront'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5777\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_tf_idf_NMF_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>statistics, scalability, modeling, machine, techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>warehouse, database, databricks, azure, pipelines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>engineering, water, traffic, drawings, construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>player, game, visualization, sql, techniques sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cell, patients, medicine, cell therapy, therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>clients, transportation, recommendations, member blend, market landscape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>platform, production, ididata, offerings capabilities, hood apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model, machine, visualization, airlines, tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>query, entities, problem concise, information entities, guideline ambiguities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>clients, autocad, engineer, building, project management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               noun_tf_idf_NMF_1\n",
       "0                         statistics, scalability, modeling, machine, techniques\n",
       "1                              warehouse, database, databricks, azure, pipelines\n",
       "2                            engineering, water, traffic, drawings, construction\n",
       "3                               player, game, visualization, sql, techniques sql\n",
       "4                                cell, patients, medicine, cell therapy, therapy\n",
       "5       clients, transportation, recommendations, member blend, market landscape\n",
       "6               platform, production, ididata, offerings capabilities, hood apps\n",
       "7                                 model, machine, visualization, airlines, tools\n",
       "8  query, entities, problem concise, information entities, guideline ambiguities\n",
       "9                       clients, autocad, engineer, building, project management"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name: ***noun_tf_idf_NMF_1***\n",
    "# Tokenizer: noun\n",
    "# Vectorizer: TF-IDF\n",
    "# Dimensionality reduction: LSA\n",
    "\n",
    "tf_idf_vc_1 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            max_df = 0.5,\n",
    "                            min_df = 0.005,\n",
    "                            stop_words = stop_words_1\n",
    "                             )\n",
    "\n",
    "components = 10  # number of components\n",
    "nmf_1 = NMF(10, random_state = 5)\n",
    "\n",
    "topics = nmf_1.fit_transform(tf_idf_vc_1.fit_transform(jobs.noun).toarray())  # reduce dimensionality\n",
    "\n",
    "print(len(tf_idf_vc_1.vocabulary_))   # number of words in dictionary\n",
    "\n",
    "# pd.DataFrame(tf_idf_vc_1.fit_transform(jobs.noun).toarray(), columns=tf_idf_vc_1.get_feature_names()).head(10)\n",
    "\n",
    "# lsa_1.components_\n",
    "# tf_idf_vc_1.get_feature_names()\n",
    "\n",
    "noun_tf_idf_NMF_1 = display_topics.topics_to_df(nmf_1, tf_idf_vc_1.get_feature_names(), 5, 'noun_tf_idf_NMF_1')  # save topics\n",
    "\n",
    "pd.set_option('max_colwidth', 200)  # display strings\n",
    "noun_tf_idf_NMF_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:41:48.978139Z",
     "start_time": "2019-11-10T22:41:48.919649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "columns=['LSA', 'NMF']\n",
    "noun_topics = pd.concat([noun_tf_idf_LSA_1, noun_tf_idf_NMF_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:41:49.870584Z",
     "start_time": "2019-11-10T22:41:49.798720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_tf_idf_LSA_1</th>\n",
       "      <th>noun_tf_idf_NMF_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>statistics, machine, modeling, techniques, results</td>\n",
       "      <td>statistics, scalability, modeling, machine, techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>warehouse, database, azure, databricks, pipelines</td>\n",
       "      <td>warehouse, database, databricks, azure, pipelines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>engineering, transportation, clients, water, traffic</td>\n",
       "      <td>engineering, water, traffic, drawings, construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>player, game, visualization, sql, sql transform</td>\n",
       "      <td>player, game, visualization, sql, techniques sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cell, patients, medicine, cell therapy, therapy</td>\n",
       "      <td>cell, patients, medicine, cell therapy, therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>clients, transportation, recommendations, businesses playerposition, clients competitors</td>\n",
       "      <td>clients, transportation, recommendations, member blend, market landscape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>platform, production, splunk, points, businesses</td>\n",
       "      <td>platform, production, ididata, offerings capabilities, hood apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>information, model, airlines, study, tools</td>\n",
       "      <td>model, machine, visualization, airlines, tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>query, entities, ambiguities engineers, holidayswe, judge</td>\n",
       "      <td>query, entities, problem concise, information entities, guideline ambiguities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>building, project management, initiative, autocad, matching profit</td>\n",
       "      <td>clients, autocad, engineer, building, project management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          noun_tf_idf_LSA_1  \\\n",
       "0                                        statistics, machine, modeling, techniques, results   \n",
       "1                                         warehouse, database, azure, databricks, pipelines   \n",
       "2                                      engineering, transportation, clients, water, traffic   \n",
       "3                                           player, game, visualization, sql, sql transform   \n",
       "4                                           cell, patients, medicine, cell therapy, therapy   \n",
       "5  clients, transportation, recommendations, businesses playerposition, clients competitors   \n",
       "6                                          platform, production, splunk, points, businesses   \n",
       "7                                                information, model, airlines, study, tools   \n",
       "8                                 query, entities, ambiguities engineers, holidayswe, judge   \n",
       "9                        building, project management, initiative, autocad, matching profit   \n",
       "\n",
       "                                                               noun_tf_idf_NMF_1  \n",
       "0                         statistics, scalability, modeling, machine, techniques  \n",
       "1                              warehouse, database, databricks, azure, pipelines  \n",
       "2                            engineering, water, traffic, drawings, construction  \n",
       "3                               player, game, visualization, sql, techniques sql  \n",
       "4                                cell, patients, medicine, cell therapy, therapy  \n",
       "5       clients, transportation, recommendations, member blend, market landscape  \n",
       "6               platform, production, ididata, offerings capabilities, hood apps  \n",
       "7                                 model, machine, visualization, airlines, tools  \n",
       "8  query, entities, problem concise, information entities, guideline ambiguities  \n",
       "9                       clients, autocad, engineer, building, project management  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma as a token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF and LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T23:09:51.954833Z",
     "start_time": "2019-11-10T23:09:41.701515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bike', 'parking', 'views', 'waterfront'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11026\n",
      "[0.03420972 0.06213072 0.04395861 0.0493622  0.04790312 0.04327154\n",
      " 0.04178091 0.0403453  0.03834841 0.03721194]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_tf_idf_LSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>technical, model, broad, big, statistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>excell, warehouse, big, database, mart report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>excell, warehouse, technical, broad, mart report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>game, big game, player, visualization, big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>patient, clinical, cell, celgene, therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>savvy, clear, interpret, drive, transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>red, proprietary, analytic, will, distribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model, air, alaska, azure, horizon air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>judge, ambiguity, query, guideline, bellevue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>porter, lundeen, porter lundeen, university, sector</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      lemma_tf_idf_LSA\n",
       "0              technical, model, broad, big, statistic\n",
       "1        excell, warehouse, big, database, mart report\n",
       "2     excell, warehouse, technical, broad, mart report\n",
       "3           game, big game, player, visualization, big\n",
       "4            patient, clinical, cell, celgene, therapy\n",
       "5       savvy, clear, interpret, drive, transportation\n",
       "6         red, proprietary, analytic, will, distribute\n",
       "7               model, air, alaska, azure, horizon air\n",
       "8         judge, ambiguity, query, guideline, bellevue\n",
       "9  porter, lundeen, porter lundeen, university, sector"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name: ***lemma_tf_idf_LSA_1***\n",
    "# Tokenizer: noun\n",
    "# Vectorizer: TF-IDF\n",
    "# Dimensionality reduction: LSA\n",
    "\n",
    "tf_idf_vc_2 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            max_df = 0.5,\n",
    "                            min_df = 0.005,\n",
    "                            stop_words = stop_words_1)   \n",
    "\n",
    "components = 10  # number of LSA components\n",
    "lsa_2 = TruncatedSVD(components, random_state = 5, algorithm='arpack')\n",
    "\n",
    "\n",
    "topics = lsa_2.fit_transform(tf_idf_vc_2.fit_transform(jobs.lemma).toarray())  # reduce dimensionality\n",
    "\n",
    "print(len(tf_idf_vc_2.vocabulary_))   # number of words in dictionary\n",
    "print(lsa_2.explained_variance_ratio_)      # explained variance\n",
    "\n",
    "# pd.DataFrame(tf_idf_vc_1.fit_transform(jobs.noun).toarray(), columns=tf_idf_vc_1.get_feature_names()).head(10)\n",
    "\n",
    "# lsa_1.components_\n",
    "# tf_idf_vc_1.get_feature_names()\n",
    "\n",
    "lemma_tf_idf_LSA = display_topics.topics_to_df(lsa_2, tf_idf_vc_2.get_feature_names(), 5, 'lemma_tf_idf_LSA')  # save topics\n",
    "\n",
    "pd.set_option('max_colwidth', 200)  # display strings\n",
    "lemma_tf_idf_LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word as a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T00:57:19.674296Z",
     "start_time": "2019-11-11T00:57:08.522147Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bike', 'parking', 'views', 'waterfront'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11592\n",
      "[0.03429688 0.06279066 0.04170626 0.04886452 0.04723526 0.04296753\n",
      " 0.04146705 0.04031894 0.03780808 0.03676268]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_tf_idf_LSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>technical, broad, modeling, big, machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>excell, big, warehouse, database, mart reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>excell, warehouse, database, mart reports, mart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gaming, big, player, play, game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>clinical, cell, celgene, patient, patients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>savvy, clients, clear, interpret, collect interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>red, proprietary, distributed, ll, highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>alaska airlines, airlines, air, alaska, azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>judge, analyze, good, bellevue, query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>lundeen, porter, porter lundeen, university, paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       word_tf_idf_LSA\n",
       "0             technical, broad, modeling, big, machine\n",
       "1       excell, big, warehouse, database, mart reports\n",
       "2      excell, warehouse, database, mart reports, mart\n",
       "3                      gaming, big, player, play, game\n",
       "4           clinical, cell, celgene, patient, patients\n",
       "5  savvy, clients, clear, interpret, collect interpret\n",
       "6            red, proprietary, distributed, ll, highly\n",
       "7        alaska airlines, airlines, air, alaska, azure\n",
       "8                judge, analyze, good, bellevue, query\n",
       "9    lundeen, porter, porter lundeen, university, paid"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name: ***lemma_tf_idf_LSA_1***\n",
    "# Tokenizer: noun\n",
    "# Vectorizer: TF-IDF\n",
    "# Dimensionality reduction: LSA\n",
    "\n",
    "tf_idf_vc_3 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            max_df = 0.5,\n",
    "                            min_df = 0.005,\n",
    "                            stop_words = stop_words_1)   \n",
    "\n",
    "components = 10  # number of LSA components\n",
    "lsa_3 = TruncatedSVD(components, random_state = 5, algorithm='arpack')\n",
    "\n",
    "\n",
    "topics = lsa_3.fit_transform(tf_idf_vc_3.fit_transform(jobs.word).toarray())  # reduce dimensionality\n",
    "\n",
    "print(len(tf_idf_vc_3.vocabulary_))   # number of words in dictionary\n",
    "print(lsa_3.explained_variance_ratio_)      # explained variance\n",
    "\n",
    "# pd.DataFrame(tf_idf_vc_1.fit_transform(jobs.noun).toarray(), columns=tf_idf_vc_1.get_feature_names()).head(10)\n",
    "\n",
    "# lsa_1.components_\n",
    "# tf_idf_vc_1.get_feature_names()\n",
    "\n",
    "word_tf_idf_LSA = display_topics.topics_to_df(lsa_3, tf_idf_vc_3.get_feature_names(), 5, 'word_tf_idf_LSA')  # save topics\n",
    "\n",
    "pd.set_option('max_colwidth', 200)  # display strings\n",
    "word_tf_idf_LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun-lemma as a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T01:13:53.080323Z",
     "start_time": "2019-11-11T01:13:47.998396Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bike', 'parking', 'views', 'waterfront'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458\n",
      "[0.02979828 0.06304829 0.0473965  0.0499364  0.04744858 0.04241423\n",
      " 0.04185172 0.03978371 0.03832084 0.03676663 0.03633249 0.03562935\n",
      " 0.02994336 0.02949124 0.02751397]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_lemma_tf_idf_LSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model, project, solution, statistic, product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>warehouse, database, process warehouse, azure, databrick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>warehouse, process warehouse, databrick, pipeline, azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>game, player, visualization, game opportunity, sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cell, patient, therapy, medicine, cell therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>transportation, trend, recommendation, audience, method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>analytic, problem platform, platform, production, ididata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>query, ambiguity, guideline, information, guideline ambiguity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>model, airline, visualization, machine, process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>project management, model, autocad, execution, member excellence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>splunk, connection, provider, network, community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>study, trial, verify, vendor, execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>study, trial, utility, plumbing, execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>water, ownership, water resource, region, verify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>verify, submittal, progress, specification, eligibility information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  noun_lemma_tf_idf_LSA\n",
       "0                          model, project, solution, statistic, product\n",
       "1              warehouse, database, process warehouse, azure, databrick\n",
       "2              warehouse, process warehouse, databrick, pipeline, azure\n",
       "3                    game, player, visualization, game opportunity, sql\n",
       "4                        cell, patient, therapy, medicine, cell therapy\n",
       "5               transportation, trend, recommendation, audience, method\n",
       "6             analytic, problem platform, platform, production, ididata\n",
       "7         query, ambiguity, guideline, information, guideline ambiguity\n",
       "8                       model, airline, visualization, machine, process\n",
       "9      project management, model, autocad, execution, member excellence\n",
       "10                     splunk, connection, provider, network, community\n",
       "11                              study, trial, verify, vendor, execution\n",
       "12                           study, trial, utility, plumbing, execution\n",
       "13                     water, ownership, water resource, region, verify\n",
       "14  verify, submittal, progress, specification, eligibility information"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name: ***lemma_tf_idf_LSA_1***\n",
    "# Tokenizer: noun\n",
    "# Vectorizer: TF-IDF\n",
    "# Dimensionality reduction: LSA\n",
    "\n",
    "tf_idf_vc_4 = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            max_df = 0.8,\n",
    "                            min_df = 0.005,\n",
    "                            stop_words = stop_words_1)   \n",
    "\n",
    "components = 15  # number of LSA components\n",
    "lsa_4 = TruncatedSVD(components, random_state = 5, algorithm='arpack')\n",
    "\n",
    "\n",
    "topics = lsa_4.fit_transform(tf_idf_vc_4.fit_transform(jobs.noun_lemma).toarray())  # reduce dimensionality\n",
    "\n",
    "print(len(tf_idf_vc_4.vocabulary_))   # number of words in dictionary\n",
    "print(lsa_4.explained_variance_ratio_)      # explained variance\n",
    "\n",
    "# pd.DataFrame(tf_idf_vc_1.fit_transform(jobs.noun).toarray(), columns=tf_idf_vc_1.get_feature_names()).head(10)\n",
    "\n",
    "# lsa_1.components_\n",
    "# tf_idf_vc_1.get_feature_names()\n",
    "\n",
    "noun_lemma_tf_idf_LSA = display_topics.topics_to_df(lsa_4, tf_idf_vc_4.get_feature_names(), 5, 'noun_lemma_tf_idf_LSA')  # save topics\n",
    "\n",
    "pd.set_option('max_colwidth', 200)  # display strings\n",
    "noun_lemma_tf_idf_LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T20:52:51.377240Z",
     "start_time": "2019-11-14T20:52:51.210279Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_n = [\n",
    "    'yearexperience', 'year', 'years', 'porch', 'work', 'home', 'term', 'datum', 'hand', 'science', 'other', \n",
    "    're', 'sex', 'gender', 'data scientist', 'data scientists', 'scientists','scientist', 'com', 'age', \n",
    "    'analyst', 'analysts', 'race','hourexperience', 'job type', 'end', 'employee', 'employees','employers', \n",
    "    'employer', 'job', 'career', 'fish', 'violet','opportunities', 'business', 'disability', 'company', \n",
    "    'companies', 'stakeholders', 'talent', 'skill', 'skills', 'team', 'teams', 'experience', 'expert', 'hands', \n",
    "    'games', 'players', 'creativity','models', 'roles', 'application', 'specifications', 'change','issues', \n",
    "    'search', 'status', 'impact', 'changes', 'location', 'detail', 'insights', 'document', 'client', 'sets', \n",
    "    'set', 'detail', 'analytics', 'fusion','applications', 'candidates','standards', 'manager', 'assets', \n",
    "    'health', 'accommodation', 'services', 'service', 'transwest', 'program', 'commute', 'utilization',\n",
    "    'technology', 'solutions', 'part', 'success', 'findings', 'notes', 'satisfaction', 'case', 'group', 'redviolet', 'trends', 'optimization',\n",
    "    'others', 'account', 'strategy', 'bike parking', 'account', 'performance','preduction', 'relationship', \n",
    "    'waterfront views', 'manage', 'quality', 'type time', 'problems', 'projects', 'people', 'collaboration', \n",
    "    'strategies', 'programs', 'partner', 'core', 'operations', 'rsu', 'plans', 'methods', 'variety', 'revenue', \n",
    "    'data', 'technologies', 'visualizations', 'type', 'life', 'safety', 'analysis', 'time', 'design', 'research', \n",
    "    'relevance', 'passion', 'customer', 'learning', 'environment', 'tasks','family', 'benefits', 'development', \n",
    "    'complete', 'industry', 'user', 'organizations', 'customers', 'documentations', 'members', 'competencies',\n",
    "    'homeowners', 'networking', 'apply', 'hire', 'homeowner', 'jobs', 'firm', 'position', 'entities',\n",
    "    'tools', 'initiative', 'servicekey', 'intents', 'merit','bonuses', 'paid', 'asset', 'candidate', \n",
    "    'building', 'sector', 'employment', 'stakeholder', 'note', 'entity', 'finding', 'staff', 'drawing',\n",
    "    'award', 'tool', 'latitude', 'view', 'button', 'matter', 'method', 'professionals', 'techniques',\n",
    "    'states', 'house', 'holidayswe', 'handyman', 'requirementsperform', 'opportunity'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T01:01:47.149987Z",
     "start_time": "2019-11-11T01:01:47.081046Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_2 = [\n",
    "    'yearexperience', 'year', 'porch', 'work', 'home', 'term', 'datum', 'hand', 'science', 'other', \n",
    "    're', 'sex', 'gender', 'data scientist', 'scientist', 'com', 'age', \n",
    "    'analyst', 'race','hourexperience', 'job type', 'end', 'employee',\n",
    "    'employer', 'job', 'career', 'fish', 'violet','opportunity', 'business', 'disability', 'company', \n",
    "    'stakeholders', 'talent', 'skill', 'team', 'experience', 'expert', \n",
    "    'player', 'creativity', 'role', 'application', 'specification', 'change','issue', \n",
    "    'search', 'status', 'impact', 'changes', 'location', 'detail', 'insight', 'document', 'client',\n",
    "    'set', 'detail', 'analytics', 'fusion','applications', 'candidates','standards', 'manager', 'asset', \n",
    "    'health', 'accommodation', 'service', 'transwest', 'program', 'commute', 'utilization',\n",
    "    'technology', 'solution', 'part', 'success', 'finding', 'satisfaction', 'case', 'group', 'redviolet', 'trends', 'optimization',\n",
    "    'account', 'strategy', 'bike parking', 'account', 'performance','preduction', 'relationship', \n",
    "    'waterfront view', 'manage', 'quality', 'type time', 'people', 'collaboration', \n",
    "    'partner', 'core', 'variety', 'revenue', \n",
    "    'data', 'type', 'life', 'safety', 'analysis', 'time', 'design', 'research', \n",
    "    'relevance', 'passion', 'customer', 'learning', 'environment', 'task','family', 'benefit', 'development', \n",
    "    'complete', 'industry', 'day', 'sector'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:08:04.437872Z",
     "start_time": "2019-11-10T22:08:04.371784Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_3 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T22:07:05.771772Z",
     "start_time": "2019-11-10T22:07:05.709771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project4/src/models/display_topics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project4/src/models/display_topics.py'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def topics_to_df(model, feature_names, no_top_words, model_name):\n",
    "    '''\n",
    "    Add topic words for dimensionality reduction to dataframe.\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    words_list = []\n",
    "    \n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        words = \", \".join([feature_names[i]for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "        words_list.append(words)\n",
    "    \n",
    "    df[model_name] = pd.Series(words_list)\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project4e]",
   "language": "python",
   "name": "conda-env-project4e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
