{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T23:22:53.817308Z",
     "start_time": "2019-11-06T23:21:37.158885Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:29:26.963262Z",
     "start_time": "2019-11-12T19:29:23.810191Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "import textcleaner\n",
    "import pickle\n",
    "import spacy\n",
    "import jieba\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import textcleaner as tc\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:29:26.992869Z",
     "start_time": "2019-11-12T19:29:26.967237Z"
    }
   },
   "outputs": [],
   "source": [
    "pickling_out = open('/Users/greenapple/project4/data/interim/data_110619_seattle_0to1k.pkl', 'rb')\n",
    "big_data = pickle.load(pickling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:30:18.851261Z",
     "start_time": "2019-11-12T19:30:18.820376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates and data rows that were inserted by indeed\n",
    "big_data.drop_duplicates(inplace=True)\n",
    "big_data.drop(big_data.loc[big_data.company_name == 'Seen by Indeed'].index, inplace=True)\n",
    "big_data.reset_index(drop=True, inplace=True)\n",
    "big_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:30:28.131481Z",
     "start_time": "2019-11-12T19:30:28.126080Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = big_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:30:34.713052Z",
     "start_time": "2019-11-12T19:30:34.638228Z"
    }
   },
   "outputs": [],
   "source": [
    "pickling_out = open('/Users/greenapple/project4/data/interim/data_110619_seattle_neg.pkl', 'rb')\n",
    "data_neg = pickle.load(pickling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:30:35.504130Z",
     "start_time": "2019-11-12T19:30:35.499214Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_set = data_neg[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:30:50.557638Z",
     "start_time": "2019-11-12T19:30:50.548656Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make test job data set\n",
    "test_data_pos = big_data[:5]\n",
    "test_data_neg  = data_neg[5:10]\n",
    "test_data = pd.concat([test_data_pos, test_data_neg])\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:31:15.000404Z",
     "start_time": "2019-11-12T19:31:14.979501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_set.drop_duplicates(inplace=True)\n",
    "neg_set.drop(neg_set.loc[neg_set.company_name == 'Seen by Indeed'].index, inplace=True)\n",
    "neg_set.reset_index(drop=True, inplace=True)\n",
    "neg_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:31:17.324651Z",
     "start_time": "2019-11-12T19:31:17.319663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect data for the rows replaced by indeed\n",
    "# replaced_data_0to1k = data_110619_seattle_set1.loc[data_110619_seattle_set1.company_name=='Seen by Indeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:31:18.025410Z",
     "start_time": "2019-11-12T19:31:18.018217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load metis resumes\n",
    "pickling_out = open('/Users/greenapple/project4/data/resumes/resumes_110719', 'rb')\n",
    "resumes_l = pickle.load(pickling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:31:18.791136Z",
     "start_time": "2019-11-12T19:31:18.784542Z"
    }
   },
   "outputs": [],
   "source": [
    "resumes = pd.DataFrame(resumes_l, columns = ['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:31:19.567886Z",
     "start_time": "2019-11-12T19:31:19.554335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ROB\\nJOHNS,\\nPH.D\\n\\nDATA SCIENTIST\\n&amp; Robjohn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>JEREMY LEHNER\\n\\nSUMMARY\\n\\nDATA SCIENTIST | D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DAVID ALEXANDER LOU\\n\\nDATA SCIENTIST | ECONOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FATIMA LOUMAINI, CSM CCBA DATA SCIENTIST\\n\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aisulu Omar\\n\\nLINKS\\n\\nPortfolio\\nhttps://www...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  ROB\\nJOHNS,\\nPH.D\\n\\nDATA SCIENTIST\\n& Robjohn...\n",
       "1  JEREMY LEHNER\\n\\nSUMMARY\\n\\nDATA SCIENTIST | D...\n",
       "2  DAVID ALEXANDER LOU\\n\\nDATA SCIENTIST | ECONOM...\n",
       "3  FATIMA LOUMAINI, CSM CCBA DATA SCIENTIST\\n\\n  ...\n",
       "4  Aisulu Omar\\n\\nLINKS\\n\\nPortfolio\\nhttps://www..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T00:12:59.978068Z",
     "start_time": "2019-11-08T00:12:59.973786Z"
    }
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:34:10.442785Z",
     "start_time": "2019-11-12T19:34:10.437136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-process text\n",
    "def pre_process(text):\n",
    "    text_sub = re.sub('[/.\\n:-]', ' ', text)  # Remove \"/\" and \".\"\n",
    "    text_sub = re.sub('[,\\(\\)]', '', text_sub).lower()  # Remove \",\" and capital letters\n",
    "    text_sub = re.sub('[^a-z\\s]', '', text_sub) # Keep alphanumer characters only\n",
    "#     re.sub('[%s]' % re.escape(string.punctuation), ' ', my_text)\n",
    "\n",
    "    return text_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:34:10.973600Z",
     "start_time": "2019-11-12T19:34:10.967916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "def tokenize_lemma(text):\n",
    "        \n",
    "    # processer = spacy.load('en')\n",
    "    tokenizer = spacy.load('en_core_web_sm')\n",
    "\n",
    "    text_obj = tokenizer(text)\n",
    "    text_str = ' '.join([token.lemma_ for token in text_obj if not token.is_stop])\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:34:11.484120Z",
     "start_time": "2019-11-12T19:34:11.478061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "def tf_idf(text1, text2):\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 2),               # vectorizer\n",
    "                        stop_words='english', \n",
    "                        token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "    X_tfidf = tfidf.fit_transform(text1).toarray()            # vectorize text1\n",
    "    Z_tfidf = tfidf.transform(text2).toarray()                # vectorize text1\n",
    "    \n",
    "    \n",
    "#     print('text1{}'.format(pd.DataFrame(X_tfidf, columns=tfidf.get_feature_names()).head(5)))\n",
    "#     print('text2{}'.format(pd.DataFrame(Z_tfidf, columns=tfidf.get_feature_names()).head(5)))\n",
    "    \n",
    "    return X_tfidf, Z_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:34:12.030169Z",
     "start_time": "2019-11-12T19:34:12.023773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce dimensionality:\n",
    "def lsa(X, Z):\n",
    "    lsa = TruncatedSVD(4)\n",
    "    X_lsa = lsa.fit_transform(X)\n",
    "    Z_lsa = lsa.transform(Z)\n",
    "  \n",
    "    \n",
    "    return X_lsa, Z_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:34:12.517348Z",
     "start_time": "2019-11-12T19:34:12.509979Z"
    }
   },
   "outputs": [],
   "source": [
    "def similarity(X_red, Z_red):\n",
    "    score = cosine_similarity(X_red, Z_red).round(2)\n",
    "    \n",
    "    column_labels = ['Resume'+str(i) for i in range(1, R_lsa.shape[0]+1)]\n",
    "    row_labels = ['Job'+str(i) for i in range(1, Z_lsa.shape[0]+1)]\n",
    "   \n",
    "    similarity_df = pd.DataFrame(score, columns=column_labels, index=row_labels)\n",
    "#     print(similarity_df)\n",
    "        \n",
    "    return similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:36:02.499060Z",
     "start_time": "2019-11-12T19:36:02.492506Z"
    }
   },
   "outputs": [],
   "source": [
    "def similarity(X_red, Z_red):\n",
    "    score = cosine_similarity(X_red, Z_red).round(2)\n",
    "    \n",
    "    column_labels = ['Resume'+str(i) for i in range(1, Z_red.shape[0]+1)]\n",
    "    row_labels = ['Job'+str(i) for i in range(1, X_red.shape[0]+1)]\n",
    "   \n",
    "    similarity_df = pd.DataFrame(score, columns=column_labels, index=row_labels)\n",
    "#     print(similarity_df)\n",
    "        \n",
    "    return similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:37:10.568573Z",
     "start_time": "2019-11-12T19:36:05.125865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/greenapple/anaconda3/envs/project4e/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Clean, lemma, tf-idf, lsa, cosine similarity\n",
    "\n",
    "train_data['text'] = train_data.description.apply(pre_process) # clean\n",
    "train_data['lemma'] = train_data.text.apply(tokenize_lemma) # tokenize and lemmatize\n",
    "\n",
    "test_data_pos['text'] = test_data_pos.description.apply(pre_process)  # clean\n",
    "test_data_pos['lemma'] = test_data_pos.text.apply(tokenize_lemma) # tokenize and lemmatize\n",
    "\n",
    "resumes['text'] = resumes.description.apply(pre_process)  # clean\n",
    "resumes['lemma'] = resumes.text.apply(tokenize_lemma) # tokenize and lemmatize\n",
    "\n",
    "Tr_tfidf, R_tfidf = tf_idf(train_data.text, resumes.text) # vectorize\n",
    "Tr_tfidf, Ts_tfidf = tf_idf(train_data.text, test_data_pos.text) # vectorize\n",
    "\n",
    "Tr_lsa, R_lsa = lsa(Tr_tfidf, R_tfidf)  # reduce dimensionality\n",
    "Tr_lsa, Ts_lsa = lsa(Tr_tfidf, Ts_tfidf)  # reduce dimensionality\n",
    "\n",
    "score = similarity(Ts_lsa, R_lsa) # cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:37:27.100856Z",
     "start_time": "2019-11-12T19:37:27.085368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume1</th>\n",
       "      <th>Resume2</th>\n",
       "      <th>Resume3</th>\n",
       "      <th>Resume4</th>\n",
       "      <th>Resume5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Job1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Job2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Job3</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Job4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Job5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Resume1  Resume2  Resume3  Resume4  Resume5\n",
       "Job1     0.74     0.81     0.66     0.69     0.79\n",
       "Job2     0.81     0.87     0.74     0.76     0.85\n",
       "Job3     0.73     0.70     0.83     0.55     0.72\n",
       "Job4     0.74     0.81     0.66     0.69     0.79\n",
       "Job5     0.95     0.97     0.89     0.93     0.96"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T19:38:02.849422Z",
     "start_time": "2019-11-12T19:38:02.824382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>link</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>red violet</td>\n",
       "      <td>Data ScientistDowntown SeattleWe’re looking fo...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data scientistdowntown seattlewere looking for...</td>\n",
       "      <td>datum scientistdowntown seattlewere look data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eXcell</td>\n",
       "      <td>As part of a leading IT managed services speci...</td>\n",
       "      <td>Database Engineer / Data Scientist</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Redmond, WA 98052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as part of a leading it managed services speci...</td>\n",
       "      <td>lead manage service specialist   associate wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Porch</td>\n",
       "      <td>Porch is looking for an accomplished, hands-on...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>porch is looking for an accomplished hands on ...</td>\n",
       "      <td>porch look accomplished hand datum scientist l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>red violet</td>\n",
       "      <td>Data ScientistDowntown SeattleWe’re looking fo...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data scientistdowntown seattlewere looking for...</td>\n",
       "      <td>datum scientistdowntown seattlewere look data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Cequint</td>\n",
       "      <td>The Splunk Analyst is responsible for supporti...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>https://www.indeed.com//rc/clk?jk=9aa6db5a5410...</td>\n",
       "      <td>Seattle, WA 98104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the splunk analyst is responsible for supporti...</td>\n",
       "      <td>splunk analyst responsible support effort datu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>TransWest</td>\n",
       "      <td>TransWest - Driving BusinessWe're looking for ...</td>\n",
       "      <td>Program Manager- Data Analyst</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$62,141 - $70,468 a year</td>\n",
       "      <td>transwest   driving businesswere looking for a...</td>\n",
       "      <td>transwest    drive businesswere look experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>University of Washington</td>\n",
       "      <td>Notes: As a UW employee, you will enjoy genero...</td>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>https://www.indeed.com//rc/clk?jk=5315b0b82919...</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>$62,141 - $70,468 a year</td>\n",
       "      <td>notes  as a uw employee you will enjoy generou...</td>\n",
       "      <td>note   uw employee enjoy generous benefit work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>We are looking for a Sr Data Scientist to help...</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>$62,141 - $70,468 a year</td>\n",
       "      <td>we are looking for a sr data scientist to help...</td>\n",
       "      <td>look sr data scientist help develop digital ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Association of Washington Cities</td>\n",
       "      <td>Association of Washington Cities (AWC) is recr...</td>\n",
       "      <td>Applications and Data Analyst</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Olympia, WA 98501</td>\n",
       "      <td>$62,141 - $70,468 a year</td>\n",
       "      <td>association of washington cities awc is recrui...</td>\n",
       "      <td>association washington cities awc recruit time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>eXcell</td>\n",
       "      <td>As part of a leading IT managed services speci...</td>\n",
       "      <td>Database Engineer / Data Scientist</td>\n",
       "      <td>https://www.indeed.com//pagead/clk?mo=r&amp;ad=-6N...</td>\n",
       "      <td>Redmond, WA 98052</td>\n",
       "      <td>$62,141 - $70,468 a year</td>\n",
       "      <td>as part of a leading it managed services speci...</td>\n",
       "      <td>lead manage service specialist   associate wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company_name  \\\n",
       "0                         red violet   \n",
       "1                             eXcell   \n",
       "2                              Porch   \n",
       "3                         red violet   \n",
       "4                            Cequint   \n",
       "..                               ...   \n",
       "95                         TransWest   \n",
       "96          University of Washington   \n",
       "97                             Tesla   \n",
       "98  Association of Washington Cities   \n",
       "99                            eXcell   \n",
       "\n",
       "                                          description  \\\n",
       "0   Data ScientistDowntown SeattleWe’re looking fo...   \n",
       "1   As part of a leading IT managed services speci...   \n",
       "2   Porch is looking for an accomplished, hands-on...   \n",
       "3   Data ScientistDowntown SeattleWe’re looking fo...   \n",
       "4   The Splunk Analyst is responsible for supporti...   \n",
       "..                                                ...   \n",
       "95  TransWest - Driving BusinessWe're looking for ...   \n",
       "96  Notes: As a UW employee, you will enjoy genero...   \n",
       "97  We are looking for a Sr Data Scientist to help...   \n",
       "98  Association of Washington Cities (AWC) is recr...   \n",
       "99  As part of a leading IT managed services speci...   \n",
       "\n",
       "                                   job_title  \\\n",
       "0                             Data Scientist   \n",
       "1         Database Engineer / Data Scientist   \n",
       "2                        Lead Data Scientist   \n",
       "3                             Data Scientist   \n",
       "4                               Data Analyst   \n",
       "..                                       ...   \n",
       "95             Program Manager- Data Analyst   \n",
       "96                     SENIOR DATA SCIENTIST   \n",
       "97  Data Scientist/Machine Learning Engineer   \n",
       "98             Applications and Data Analyst   \n",
       "99        Database Engineer / Data Scientist   \n",
       "\n",
       "                                                 link             location  \\\n",
       "0   https://www.indeed.com//pagead/clk?mo=r&ad=-6N...         Seattle, WA    \n",
       "1   https://www.indeed.com//pagead/clk?mo=r&ad=-6N...   Redmond, WA 98052    \n",
       "2   https://www.indeed.com//pagead/clk?mo=r&ad=-6N...         Seattle, WA    \n",
       "3   https://www.indeed.com//pagead/clk?mo=r&ad=-6N...         Seattle, WA    \n",
       "4   https://www.indeed.com//rc/clk?jk=9aa6db5a5410...   Seattle, WA 98104    \n",
       "..                                                ...                  ...   \n",
       "95  https://www.indeed.com//pagead/clk?mo=r&ad=-6N...        Data Analyst    \n",
       "96  https://www.indeed.com//rc/clk?jk=5315b0b82919...         Seattle, WA    \n",
       "97  https://www.indeed.com//pagead/clk?mo=r&ad=-6N...         Seattle, WA    \n",
       "98  https://www.indeed.com//pagead/clk?mo=r&ad=-6N...   Olympia, WA 98501    \n",
       "99  https://www.indeed.com//pagead/clk?mo=r&ad=-6N...   Redmond, WA 98052    \n",
       "\n",
       "                      salary  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "..                       ...   \n",
       "95  $62,141 - $70,468 a year   \n",
       "96  $62,141 - $70,468 a year   \n",
       "97  $62,141 - $70,468 a year   \n",
       "98  $62,141 - $70,468 a year   \n",
       "99  $62,141 - $70,468 a year   \n",
       "\n",
       "                                                 text  \\\n",
       "0   data scientistdowntown seattlewere looking for...   \n",
       "1   as part of a leading it managed services speci...   \n",
       "2   porch is looking for an accomplished hands on ...   \n",
       "3   data scientistdowntown seattlewere looking for...   \n",
       "4   the splunk analyst is responsible for supporti...   \n",
       "..                                                ...   \n",
       "95  transwest   driving businesswere looking for a...   \n",
       "96  notes  as a uw employee you will enjoy generou...   \n",
       "97  we are looking for a sr data scientist to help...   \n",
       "98  association of washington cities awc is recrui...   \n",
       "99  as part of a leading it managed services speci...   \n",
       "\n",
       "                                                lemma  \n",
       "0   datum scientistdowntown seattlewere look data ...  \n",
       "1   lead manage service specialist   associate wor...  \n",
       "2   porch look accomplished hand datum scientist l...  \n",
       "3   datum scientistdowntown seattlewere look data ...  \n",
       "4   splunk analyst responsible support effort datu...  \n",
       "..                                                ...  \n",
       "95  transwest    drive businesswere look experienc...  \n",
       "96  note   uw employee enjoy generous benefit work...  \n",
       "97  look sr data scientist help develop digital ma...  \n",
       "98  association washington cities awc recruit time...  \n",
       "99  lead manage service specialist   associate wor...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project4e]",
   "language": "python",
   "name": "conda-env-project4e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
